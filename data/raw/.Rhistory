for (idStart in fullRange){
idRange <- idStart:(idStart + (sectionSize -1))      # one less than the range jump
print(paste('First station ID in range is', idStart))
idRangeString <- lapply(idRange, function(x) toString(x, width = NULL))                  # single-column DF of strings with a strange [[x]] CRLF [1] "3211" appearance
aqiStationAddresses <- lapply(idRangeString[[1]], function(x) paste0("http://api.waqi.info/feed/@", idRangeString[], "/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"))
for (thisRow in idStart:length(idRangeString)) {
thisStation <- aqiStationAddresses[[1]][thisRow]
print(paste('AQI station', thisStation))
try(response <- fromJSON(txt = thisStation), silent = TRUE)
checkCoords <- NULL
if (response$status == "ok") {  ### new line & brackets
try(checkCoords <- list(response$data$idx, response$data$city$geo[1], response$data$city$geo[2], response$data$city$name, response$data$city$url))# was   , silent = TRUE)
if (!is.null(response$data$city$geo[1]) & !is.null(response$data$city$geo[2])) {
if ((southExtent < checkCoords[2] & northExtent > checkCoords[2] & eastExtent > checkCoords[3] & westExtent < checkCoords[3]) |
(southExtent < checkCoords[3] & northExtent > checkCoords[3] & eastExtent > checkCoords[2] & westExtent < checkCoords[2])) {   # some station co-ordinates were entered as lon, lat
print(paste0(checkCoords[4], ' is in the bounding box.'))
try(aqiStationsDF0[nrow(aqiStationsDF0) + 1,] <- list(response$data$idx, response$data$city$geo[1], response$data$city$geo[2], response$data$city$name, response$data$city$url), silent = TRUE)
}
else {
print(paste0(checkCoords[4], ' is out of bounds.'))
}
return
}
response$status <- "reset"
}
Sys.sleep(0.1)                                                      # capital Sys
}
write_csv(aqiStationsDF0, path = '/home/jay/c3/citiesAQI/data/raw/ukAqiStations-3.csv', na = 'NA', append = TRUE, col_names = TRUE)
stopTime <- Sys.time()
timeTaken <- stopTime - goTime
print(timeTaken)
Sys.sleep(16.0)
}
# 2020-04-10
# import AQI from www.aqi.info api
# sample request curl -i "http://api.waqi.info/feed/@3211/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"
# error that breaks it is "Error : $ operator is invalid for atomic vectors".  First restart at 9500, second at 10500, then 11550
# intialise ----------------------------------------------------------------
# from https://www.r-bloggers.com/accessing-apis-from-r-and-a-little-r-programming/
setwd('/home/jay/R/aqi/data/raw')
library('tidyverse')
library('jsonlite')
library('httr')
library('lubridate')
library('sys')                                                        # not sure if this is needed
northExtent <- 61.0
southExtent <- 49.5
eastExtent <- 2.0
westExtent <- -10.5
# first few stations in Canada northTest <- 45.0 southTest <- 41.0 eastTest <- -79.0 westTest <- -80.5
aqiStationsDF0 <- data.frame('stationIDX', 'lat', 'lon', 'name', 'url', stringsAsFactors = FALSE)
# loop through AQI stations -------------------------------------------------
goTime <- Sys.time()                # fullRange <- seq(0, 12000, by = 3000)   # top of range is 13295 broken into batches of 3000 queries to keep aqicn happy
sectionSize <- 1000
fullRange <- seq(1, 12001, by = sectionSize)       # UK stations start below ~2800
for (idStart in fullRange){
idRange <- idStart:(idStart + (sectionSize -1))      # one less than the range jump
print(paste('First station ID in range is', idStart))
idRangeString <- lapply(idRange, function(x) toString(x, width = NULL))                  # single-column DF of strings with a strange [[x]] CRLF [1] "3211" appearance
aqiStationAddresses <- lapply(idRangeString[[1]], function(x) paste0("http://api.waqi.info/feed/@", idRangeString[], "/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"))
for (thisRow in idStart:length(idRangeString)) {
thisStation <- aqiStationAddresses[[1]][thisRow]
print(paste('AQI station', thisStation))
try(response <- fromJSON(txt = thisStation), silent = TRUE)
checkCoords <- NULL
if (response$status == "ok") {  ### new line & brackets
try(checkCoords <- list(response$data$idx, response$data$city$geo[1], response$data$city$geo[2], response$data$city$name, response$data$city$url))# was   , silent = TRUE)
if (!is.null(response$data$city$geo[1]) & !is.null(response$data$city$geo[2])) {
if ((southExtent < checkCoords[2] & northExtent > checkCoords[2] & eastExtent > checkCoords[3] & westExtent < checkCoords[3]) |
(southExtent < checkCoords[3] & northExtent > checkCoords[3] & eastExtent > checkCoords[2] & westExtent < checkCoords[2])) {   # some station co-ordinates were entered as lon, lat
print(paste0(checkCoords[4], ' is in the bounding box.'))
try(aqiStationsDF0[nrow(aqiStationsDF0) + 1,] <- list(response$data$idx, response$data$city$geo[1], response$data$city$geo[2], response$data$city$name, response$data$city$url), silent = TRUE)
}
else {
print(paste0(checkCoords[4], ' is out of bounds.'))
}
return
}
response$status <- "reset"
}
Sys.sleep(0.1)                                                      # capital Sys
}
write_csv(aqiStationsDF0, path = '/home/jay/c3/citiesAQI/data/raw/ukAqiStations-4.csv', na = 'NA', append = TRUE, col_names = TRUE)
stopTime <- Sys.time()
timeTaken <- stopTime - goTime
print(timeTaken)
Sys.sleep(16.0)
}
# 2020-04-10
# import AQI from www.aqi.info api
# sample request curl -i "http://api.waqi.info/feed/@3211/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"
# error that breaks it is "Error : $ operator is invalid for atomic vectors".  First restart at 9500, second at 10500, then 11550
# intialise ----------------------------------------------------------------
# from https://www.r-bloggers.com/accessing-apis-from-r-and-a-little-r-programming/
setwd('/home/jay/R/aqi/data/raw')
library('tidyverse')
library('jsonlite')
library('httr')
library('lubridate')
library('sys')                                                        # not sure if this is needed
northExtent <- 61.0
southExtent <- 49.5
eastExtent <- 2.0
westExtent <- -10.5
# first few stations in Canada northTest <- 45.0 southTest <- 41.0 eastTest <- -79.0 westTest <- -80.5
aqiStationsDF0 <- data.frame('stationIDX', 'lat', 'lon', 'name', 'url', stringsAsFactors = FALSE)
# loop through AQI stations -------------------------------------------------
goTime <- Sys.time()                # fullRange <- seq(0, 12000, by = 3000)   # top of range is 13295 broken into batches of 3000 queries to keep aqicn happy
sectionSize <- 10
fullRange <- seq(3140, 3180, by = sectionSize)       # UK stations start below ~2800
for (idStart in fullRange){
idRange <- idStart:(idStart + (sectionSize -1))      # one less than the range jump
print(paste('First station ID in range is', idStart))
idRangeString <- lapply(idRange, function(x) toString(x, width = NULL))                  # single-column DF of strings with a strange [[x]] CRLF [1] "3211" appearance
aqiStationAddresses <- lapply(idRangeString[[1]], function(x) paste0("http://api.waqi.info/feed/@", idRangeString[], "/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"))
for (thisRow in 1:length(idRangeString)) {
thisStation <- aqiStationAddresses[[1]][thisRow]
print(paste('AQI station', thisStation))
try(response <- fromJSON(txt = thisStation), silent = TRUE)
checkCoords <- NULL
if (response$status == "ok") {  ### new line & brackets
try(checkCoords <- list(response$data$idx, response$data$city$geo[1], response$data$city$geo[2], response$data$city$name, response$data$city$url))# was   , silent = TRUE)
if (!is.null(response$data$city$geo[1]) & !is.null(response$data$city$geo[2])) {
if ((southExtent < checkCoords[2] & northExtent > checkCoords[2] & eastExtent > checkCoords[3] & westExtent < checkCoords[3]) |
(southExtent < checkCoords[3] & northExtent > checkCoords[3] & eastExtent > checkCoords[2] & westExtent < checkCoords[2])) {   # some station co-ordinates were entered as lon, lat
print(paste0(checkCoords[4], ' is in the bounding box.'))
try(aqiStationsDF0[nrow(aqiStationsDF0) + 1,] <- list(response$data$idx, response$data$city$geo[1], response$data$city$geo[2], response$data$city$name, response$data$city$url), silent = TRUE)
}
else {
print(paste0(checkCoords[4], ' is out of bounds.'))
}
return
}
response$status <- "reset"
}
Sys.sleep(0.1)                                                      # capital Sys
}
write_csv(aqiStationsDF0, path = '/home/jay/c3/citiesAQI/data/raw/ukAqiStations-4test0.csv', na = 'NA', append = TRUE, col_names = TRUE)
stopTime <- Sys.time()
timeTaken <- stopTime - goTime
print(timeTaken)
Sys.sleep(16.0)
}
print(timeTaken)
# 2020-04-10
# import AQI from www.aqi.info api
# sample request curl -i "http://api.waqi.info/feed/@3211/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"
# error that breaks it is "Error : $ operator is invalid for atomic vectors".  First restart at 9500, second at 10500, then 11550
# intialise ----------------------------------------------------------------
# from https://www.r-bloggers.com/accessing-apis-from-r-and-a-little-r-programming/
setwd('/home/jay/R/aqi/data/raw')
library('tidyverse')
library('jsonlite')
library('httr')
library('lubridate')
library('sys')                                                        # not sure if this is needed
northExtent <- 61.0
southExtent <- 49.5
eastExtent <- 2.0
westExtent <- -10.5
# first few stations in Canada northTest <- 45.0 southTest <- 41.0 eastTest <- -79.0 westTest <- -80.5
aqiStationsDF0 <- data.frame('stationIDX', 'lat', 'lon', 'name', 'url', stringsAsFactors = FALSE)
# loop through AQI stations -------------------------------------------------
goTime <- Sys.time()                # fullRange <- seq(0, 12000, by = 3000)   # top of range is 13295 broken into batches of 3000 queries to keep aqicn happy
sectionSize <- 10
fullRange <- seq(3140, 3180, by = sectionSize)       # UK stations start below ~2800
for (idStart in fullRange){
idRange <- idStart:(idStart + (sectionSize -1))      # one less than the range jump
print(paste('First station ID in range is', idStart))
idRangeString <- lapply(idRange, function(x) toString(x, width = NULL))                  # single-column DF of strings with a strange [[x]] CRLF [1] "3211" appearance
aqiStationAddresses <- lapply(idRangeString[[1]], function(x) paste0("http://api.waqi.info/feed/@", idRangeString[], "/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"))
for (thisRow in 1:length(idRangeString)) {
thisStation <- aqiStationAddresses[[1]][thisRow]
print(paste('AQI station', thisStation))
try(response <- fromJSON(txt = thisStation), silent = TRUE)
checkCoords <- NULL
if (response$status == "ok") {  ### new line & brackets
try(checkCoords <- list(response$data$idx, response$data$city$geo[1], response$data$city$geo[2], response$data$city$name, response$data$city$url))# was   , silent = TRUE)
if (!is.null(response$data$city$geo[1]) & !is.null(response$data$city$geo[2])) {
if ((southExtent < checkCoords[2] & northExtent > checkCoords[2] & eastExtent > checkCoords[3] & westExtent < checkCoords[3]) |
(southExtent < checkCoords[3] & northExtent > checkCoords[3] & eastExtent > checkCoords[2] & westExtent < checkCoords[2])) {   # some station co-ordinates were entered as lon, lat
print(paste0(checkCoords[4], ' is in the bounding box.'))
try(aqiStationsDF0[nrow(aqiStationsDF0) + 1,] <- list(response$data$idx, response$data$city$geo[1], response$data$city$geo[2], response$data$city$name, response$data$city$url), silent = TRUE)
}
else {
print(paste0(checkCoords[4], ' is out of bounds.'))
}
return
}
response$status <- "reset"
}
Sys.sleep(0.1)                                                      # capital Sys
}
Sys.sleep(16.0)
}
write_csv(aqiStationsDF0, path = '/home/jay/c3/citiesAQI/data/raw/ukAqiStations-4test1.csv', na = 'NA', append = TRUE, col_names = TRUE)
stopTime <- Sys.time()
timeTaken <- stopTime - goTime
print(timeTaken)
aqiStationsDF1 <- data.frame('stationIDX', 'lat', 'lon', 'name', 'url', stringsAsFactors = FALSE)
aqiStationsDF1
aqiStationsDF2 <- data.frame('stationIDX', 'lat', 'lon', 'name', 'url', stringsAsFactors = TRUE)
aqiStationsDF2
write_csv(aqiStationsDF0, path = '/home/jay/c3/citiesAQI/data/raw/ukAqiStations-4test1TRUE.csv', na = 'NA', append = TRUE, col_names = TRUE)
write_csv(aqiStationsDF0, path = '/home/jay/c3/citiesAQI/data/raw/ukAqiStations-4test1FALSE.csv', na = 'NA', append = TRUE, col_names = FALSE)
# 2020-04-10
# import AQI from www.aqi.info api
# sample request curl -i "http://api.waqi.info/feed/@3211/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"
# error that breaks it is "Error : $ operator is invalid for atomic vectors".  First restart at 9500, second at 10500, then 11550
# intialise ----------------------------------------------------------------
# from https://www.r-bloggers.com/accessing-apis-from-r-and-a-little-r-programming/
setwd('/home/jay/R/aqi/data/raw')
library('tidyverse')
library('jsonlite')
library('httr')
library('lubridate')
library('sys')                                                        # not sure if this is needed
northExtent <- 61.0
southExtent <- 49.5
eastExtent <- 2.0
westExtent <- -10.5
# first few stations in Canada northTest <- 45.0 southTest <- 41.0 eastTest <- -79.0 westTest <- -80.5
aqiStationsDF0 <- data.frame('stationIDX', 'lat', 'lon', 'name', 'url', stringsAsFactors = FALSE)
# loop through AQI stations -------------------------------------------------
goTime <- Sys.time()                # fullRange <- seq(0, 12000, by = 3000)   # top of range is 13295 broken into batches of 3000 queries to keep aqicn happy
sectionSize <- 10
fullRange <- seq(3140, 3180, by = sectionSize)       # UK stations start below ~2800
for (idStart in fullRange){
idRange <- idStart:(idStart + (sectionSize -1))      # one less than the range jump
print(paste('First station ID in range is', idStart))
idRangeString <- lapply(idRange, function(x) toString(x, width = NULL))                  # single-column DF of strings with a strange [[x]] CRLF [1] "3211" appearance
aqiStationAddresses <- lapply(idRangeString[[1]], function(x) paste0("http://api.waqi.info/feed/@", idRangeString[], "/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"))
for (thisRow in 1:length(idRangeString)) {
thisStation <- aqiStationAddresses[[1]][thisRow]
print(paste('AQI station', thisStation))
try(response <- fromJSON(txt = thisStation), silent = TRUE)
checkCoords <- NULL
if (response$status == "ok") {  ### new line & brackets
try(checkCoords <- list(response$data$idx, response$data$city$geo[1], response$data$city$geo[2], response$data$city$name, response$data$city$url))# was   , silent = TRUE)
if (!is.null(response$data$city$geo[1]) & !is.null(response$data$city$geo[2])) {
if ((southExtent < checkCoords[2] & northExtent > checkCoords[2] & eastExtent > checkCoords[3] & westExtent < checkCoords[3]) |
(southExtent < checkCoords[3] & northExtent > checkCoords[3] & eastExtent > checkCoords[2] & westExtent < checkCoords[2])) {   # some station co-ordinates were entered as lon, lat
print(paste0(checkCoords[4], ' is in the bounding box.'))
try(aqiStationsDF0[nrow(aqiStationsDF0) + 1,] <- list(response$data$idx, response$data$city$geo[1], response$data$city$geo[2], response$data$city$name, response$data$city$url), silent = TRUE)
}
else {
print(paste0(checkCoords[4], ' is out of bounds.'))
}
return
}
response$status <- "reset"
}
Sys.sleep(0.1)                                                      # capital Sys
}
Sys.sleep(16.0)
}
write_csv(aqiStationsDF0, path = '/home/jay/c3/citiesAQI/data/raw/ukAqiStations-4.csv', na = 'NA', append = TRUE, col_names = FALSE)
stopTime <- Sys.time()
timeTaken <- stopTime - goTime
print(timeTaken)
# 2020-04-10
# import AQI from www.aqi.info api
# sample request curl -i "http://api.waqi.info/feed/@3211/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"
# error that breaks it is "Error : $ operator is invalid for atomic vectors".  First restart at 9500, second at 10500, then 11550
# intialise ----------------------------------------------------------------
# from https://www.r-bloggers.com/accessing-apis-from-r-and-a-little-r-programming/
setwd('/home/jay/R/aqi/data/raw')
library('tidyverse')
library('jsonlite')
library('httr')
library('lubridate')
library('sys')                                                        # not sure if this is needed
northExtent <- 61.0
southExtent <- 49.5
eastExtent <- 2.0
westExtent <- -10.5
# first few stations in Canada northTest <- 45.0 southTest <- 41.0 eastTest <- -79.0 westTest <- -80.5
aqiStationsDF0 <- data.frame('stationIDX', 'lat', 'lon', 'name', 'url', stringsAsFactors = FALSE)
# loop through AQI stations -------------------------------------------------
goTime <- Sys.time()                # fullRange <- seq(0, 12000, by = 3000)   # top of range is 13295 broken into batches of 3000 queries to keep aqicn happy
sectionSize <- 1000
fullRange <- seq(0, 12000, by = sectionSize)       # UK stations start below ~2800
for (idStart in fullRange){
idRange <- idStart:(idStart + (sectionSize -1))      # one less than the range jump
print(paste('First station ID in range is', idStart))
idRangeString <- lapply(idRange, function(x) toString(x, width = NULL))                  # single-column DF of strings with a strange [[x]] CRLF [1] "3211" appearance
aqiStationAddresses <- lapply(idRangeString[[1]], function(x) paste0("http://api.waqi.info/feed/@", idRangeString[], "/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"))
for (thisRow in 1:length(idRangeString)) {
thisStation <- aqiStationAddresses[[1]][thisRow]
print(paste('AQI station', thisStation))
try(response <- fromJSON(txt = thisStation), silent = TRUE)
checkCoords <- NULL
if (response$status == "ok") {  ### new line & brackets
try(checkCoords <- list(response$data$idx, response$data$city$geo[1], response$data$city$geo[2], response$data$city$name, response$data$city$url))# was   , silent = TRUE)
if (!is.null(response$data$city$geo[1]) & !is.null(response$data$city$geo[2])) {
if ((southExtent < checkCoords[2] & northExtent > checkCoords[2] & eastExtent > checkCoords[3] & westExtent < checkCoords[3]) |
(southExtent < checkCoords[3] & northExtent > checkCoords[3] & eastExtent > checkCoords[2] & westExtent < checkCoords[2])) {   # some station co-ordinates were entered as lon, lat
print(paste0(checkCoords[4], ' is in the bounding box.'))
try(aqiStationsDF0[nrow(aqiStationsDF0) + 1,] <- list(response$data$idx, response$data$city$geo[1], response$data$city$geo[2], response$data$city$name, response$data$city$url), silent = TRUE)
}
else {
print(paste0(checkCoords[4], ' is out of bounds.'))
}
return
}
response$status <- "reset"
}
Sys.sleep(0.1)                                                      # capital Sys
}
Sys.sleep(16.0)
}
# 2020-04-10
# import AQI from www.aqi.info api
# sample request curl -i "http://api.waqi.info/feed/@3211/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"
# error that breaks it is "Error : $ operator is invalid for atomic vectors".  First restart at 9500, second at 10500, then 11550
# intialise ----------------------------------------------------------------
# from https://www.r-bloggers.com/accessing-apis-from-r-and-a-little-r-programming/
setwd('/home/jay/R/aqi/data/raw')
library('tidyverse')
library('jsonlite')
library('httr')
library('lubridate')
library('sys')                                                        # not sure if this is needed
northExtent <- 61.0
southExtent <- 49.5
eastExtent <- 2.0
westExtent <- -10.5
# first few stations in Canada northTest <- 45.0 southTest <- 41.0 eastTest <- -79.0 westTest <- -80.5
aqiStationsDF0 <- data.frame('stationIDX', 'lat', 'lon', 'name', 'url', stringsAsFactors = FALSE)
# loop through AQI stations -------------------------------------------------
goTime <- Sys.time()                # fullRange <- seq(0, 12000, by = 3000)   # top of range is 13295 broken into batches of 3000 queries to keep aqicn happy
sectionSize <- 1000
fullRange <- seq(0, 12000, by = sectionSize)       # UK stations start below ~2800
for (idStart in fullRange){
idRange <- idStart:(idStart + (sectionSize -1))      # one less than the range jump
print(paste('First station ID in range is', idStart))
idRangeString <- lapply(idRange, function(x) toString(x, width = NULL))                  # single-column DF of strings with a strange [[x]] CRLF [1] "3211" appearance
aqiStationAddresses <- lapply(idRangeString[[1]], function(x) paste0("http://api.waqi.info/feed/@", idRangeString[], "/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"))
for (thisRow in 1:length(idRangeString)) {
thisStation <- aqiStationAddresses[[1]][thisRow]
print(paste('AQI station', thisStation))
try(response <- fromJSON(txt = thisStation), silent = TRUE)
checkCoords <- NULL
if (response$status == "ok") {  ### new line & brackets
try(checkCoords <- list(response$data$idx, response$data$city$geo[1], response$data$city$geo[2], response$data$city$name, response$data$city$url))# was   , silent = TRUE)
if (!is.null(response$data$city$geo[1]) & !is.null(response$data$city$geo[2])) {
if ((southExtent < checkCoords[2] & northExtent > checkCoords[2] & eastExtent > checkCoords[3] & westExtent < checkCoords[3]) |
(southExtent < checkCoords[3] & northExtent > checkCoords[3] & eastExtent > checkCoords[2] & westExtent < checkCoords[2])) {   # some station co-ordinates were entered as lon, lat
print(paste0(checkCoords[4], ' is in the bounding box.'))
try(aqiStationsDF0[nrow(aqiStationsDF0) + 1,] <- list(response$data$idx, response$data$city$geo[1], response$data$city$geo[2], response$data$city$name, response$data$city$url), silent = TRUE)
}
else {
print(paste0(checkCoords[4], ' is out of bounds.'))
}
return
}
response$status <- "reset"
}
Sys.sleep(0.1)                                                      # capital Sys
}
Sys.sleep(16.0)
}
write_csv(aqiStationsDF0, path = '/home/jay/c3/citiesAQI/data/raw/ukAqiStations-4.csv', na = 'NA', append = TRUE, col_names = FALSE)
stopTime <- Sys.time()
timeTaken <- stopTime - goTime
print(timeTaken)
testTime <- 7.6544
sprintf("%.1f", testTime)
# present geographic spread of AQI monitoring stations across Great Britain & Ireland
library('tidyverse')
library('maps')
library('mapdata')
# present geographic spread of AQI monitoring stations across Great Britain & Ireland
#library('tidyverse')
install.packages('maps')
install.packages('mapdata')
library('maps')
library('mapdata')
setwd("~/c3/citiesForGit/src/data")
setwd("~/c3/citiesAQIForGit/src/data")
setwd("~/c3/citiesAQIforGit/src/data")
getwd()
# get AQI data for UK stations from www.aqi.info api
# only ~300 stations so there should be  no need for 16s delays as used in etlFindUKstations-4.R
# example for station 8070, Norfolk
# apiReq <- "http://api.waqi.info/feed/@8070/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"
# aqiData <- fromJSON(txt = apiReq)
# see references folder for details in JSONdownloadExplained.txt
library('tidyverse')
library('jsonlite')
library('httr')
library('lubridate')
library('sys')
fnNULLtoNA <- function(pollutantValue)
if (is.null(pollutantValue)) {
score <- NA
} else {
score <- pollutantValue
}
return(score)
setwd('~/c3/citiesAQIforGit/data/raw')
boxStations <- read.csv('StationLocations.csv')
boxID <- boxStations[,c('stationIDX')]
for (islandRun in 1:80){
stnReports <- data.frame('idx', 'humidity', 'pressure', 'temp', 'dominant', 'pm10', 'pm2-5', 'co', 'no2', 'o3', 'so2', 't-local', 't-zone', 't-univ', 't-iso', stringsAsFactors = FALSE)
goTime <- Sys.time()
for (i in 1:length(boxID)) {
waqiAccess <- paste0("http://api.waqi.info/feed/@", boxID[i], "/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947")
try(APIreply <- fromJSON(txt = waqiAccess), silent = TRUE)
if (APIreply$status == "ok") {
###print(paste(APIreply$data$city$name, "- station ID", APIreply$data$idx))
try(stnReports[nrow(stnReports) + 1,] <- list(APIreply$data$idx, APIreply$data$iaqi$h$v, APIreply$data$iaqi$p$v, APIreply$data$iaqi$t$v, APIreply$data$dominentpol, fnNULLtoNA(APIreply$data$iaqi$pm10$v), fnNULLtoNA(APIreply$data$iaqi$pm25$v), fnNULLtoNA(APIreply$data$iaqi$co$v), fnNULLtoNA(APIreply$data$iaqi$no2$v), fnNULLtoNA(APIreply$data$iaqi$o3$v), fnNULLtoNA(APIreply$data$iaqi$so2$v), APIreply$data$time$s, APIreply$data$time$tz, APIreply$data$time$v, APIreply$data$time$iso), silent = TRUE)
}
Sys.sleep(0.1)
}
csvName <- paste0(format(now(), "%Y%m%d_%H%M"), "aqiUKEire.csv")
write.csv(stnReports, csvName, na = 'NA')
#write.csv(stnReports, csvName, append = TRUE, na = 'NA', col.names = FALSE)
###print(paste('Saved csv', islandRun))
stopTime <- Sys.time()
timeTaken <- stopTime - goTime
###print(paste('Run', islandRun, 'took', sprintf("%.1f", timeTaken), 'minutes'))
Sys.sleep(750)  # wait twelve-and-a-half minutes, gives roughly half-hour intervals because it takes ~16 mins to get 308? stations data
}
getwd()
getwd()
# get AQI data for UK stations from www.aqi.info api
# only ~300 stations so there should be  no need for 16s delays as used in etlFindUKstations-4.R
# example for station 8070, Norfolk
# apiReq <- "http://api.waqi.info/feed/@8070/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"
# aqiData <- fromJSON(txt = apiReq)
# see references folder for details in JSONdownloadExplained.txt
library('tidyverse')
library('jsonlite')
library('httr')
library('lubridate')
library('sys')
fnNULLtoNA <- function(pollutantValue)
if (is.null(pollutantValue)) {
score <- NA
} else {
score <- pollutantValue
}
return(score)
setwd('~/c3/citiesAQIforGit/data/raw')
boxStations <- read.csv('StationLocations.csv')
boxID <- boxStations[,c('stationIDX')]
for (islandRun in 1:80){
stnReports <- data.frame('idx', 'humidity', 'pressure', 'temp', 'dominant', 'pm10', 'pm2-5', 'co', 'no2', 'o3', 'so2', 't-local', 't-zone', 't-univ', 't-iso', stringsAsFactors = FALSE)
goTime <- Sys.time()
for (i in 1:length(boxID)) {
waqiAccess <- paste0("http://api.waqi.info/feed/@", boxID[i], "/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947")
try(APIreply <- fromJSON(txt = waqiAccess), silent = TRUE)
if (APIreply$status == "ok") {
###print(paste(APIreply$data$city$name, "- station ID", APIreply$data$idx))
try(stnReports[nrow(stnReports) + 1,] <- list(APIreply$data$idx, APIreply$data$iaqi$h$v, APIreply$data$iaqi$p$v, APIreply$data$iaqi$t$v, APIreply$data$dominentpol, fnNULLtoNA(APIreply$data$iaqi$pm10$v), fnNULLtoNA(APIreply$data$iaqi$pm25$v), fnNULLtoNA(APIreply$data$iaqi$co$v), fnNULLtoNA(APIreply$data$iaqi$no2$v), fnNULLtoNA(APIreply$data$iaqi$o3$v), fnNULLtoNA(APIreply$data$iaqi$so2$v), APIreply$data$time$s, APIreply$data$time$tz, APIreply$data$time$v, APIreply$data$time$iso), silent = TRUE)
}
Sys.sleep(0.1)
}
csvName <- paste0(format(now(), "%Y%m%d_%H%M"), "aqiUKEire.csv")
write.csv(stnReports, csvName, na = 'NA')
#write.csv(stnReports, csvName, append = TRUE, na = 'NA', col.names = FALSE)
###print(paste('Saved csv', islandRun))
stopTime <- Sys.time()
timeTaken <- stopTime - goTime
###print(paste('Run', islandRun, 'took', sprintf("%.1f", timeTaken), 'minutes'))
Sys.sleep(750)  # wait twelve-and-a-half minutes, gives roughly half-hour intervals because it takes ~16 mins to get 308? stations data
}
install.packages("tidyverse")
install.packages("tidyverse")
# get AQI data for UK stations from www.aqi.info api
# only ~300 stations so there should be  no need for 16s delays as used in etlFindUKstations-4.R
# example for station 8070, Norfolk
# apiReq <- "http://api.waqi.info/feed/@8070/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947"
# aqiData <- fromJSON(txt = apiReq)
# see references folder for details in JSONdownloadExplained.txt
library('tidyverse')
library('jsonlite')
library('httr')
library('lubridate')
library('sys')
fnNULLtoNA <- function(pollutantValue)
if (is.null(pollutantValue)) {
score <- NA
} else {
score <- pollutantValue
}
return(score)
setwd('~/c3/citiesAQIforGit/data/raw')
boxStations <- read.csv('StationLocations.csv')
boxID <- boxStations[,c('stationIDX')]
for (islandRun in 1:80){
stnReports <- data.frame('idx', 'humidity', 'pressure', 'temp', 'dominant', 'pm10', 'pm2-5', 'co', 'no2', 'o3', 'so2', 't-local', 't-zone', 't-univ', 't-iso', stringsAsFactors = FALSE)
goTime <- Sys.time()
for (i in 1:length(boxID)) {
waqiAccess <- paste0("http://api.waqi.info/feed/@", boxID[i], "/?token=67d23a5ad81a0557c4be19eb43dbc1d10eeaf947")
try(APIreply <- fromJSON(txt = waqiAccess), silent = TRUE)
if (APIreply$status == "ok") {
###print(paste(APIreply$data$city$name, "- station ID", APIreply$data$idx))
try(stnReports[nrow(stnReports) + 1,] <- list(APIreply$data$idx, APIreply$data$iaqi$h$v, APIreply$data$iaqi$p$v, APIreply$data$iaqi$t$v, APIreply$data$dominentpol, fnNULLtoNA(APIreply$data$iaqi$pm10$v), fnNULLtoNA(APIreply$data$iaqi$pm25$v), fnNULLtoNA(APIreply$data$iaqi$co$v), fnNULLtoNA(APIreply$data$iaqi$no2$v), fnNULLtoNA(APIreply$data$iaqi$o3$v), fnNULLtoNA(APIreply$data$iaqi$so2$v), APIreply$data$time$s, APIreply$data$time$tz, APIreply$data$time$v, APIreply$data$time$iso), silent = TRUE)
}
Sys.sleep(0.1)
}
csvName <- paste0(format(now(), "%Y%m%d_%H%M"), "aqiUKEire.csv")
write.csv(stnReports, csvName, na = 'NA')
#write.csv(stnReports, csvName, append = TRUE, na = 'NA', col.names = FALSE)
###print(paste('Saved csv', islandRun))
stopTime <- Sys.time()
timeTaken <- stopTime - goTime
###print(paste('Run', islandRun, 'took', sprintf("%.1f", timeTaken), 'minutes'))
Sys.sleep(750)  # wait twelve-and-a-half minutes, gives roughly half-hour intervals because it takes ~16 mins to get 308? stations data
}
